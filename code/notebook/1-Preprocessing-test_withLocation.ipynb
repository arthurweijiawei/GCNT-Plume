{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Author: Ankit Kariryaa, University of Bremen\n",
    "   \n",
    "   Modified by Jiawei Wei\n",
    "   \n",
    "\n",
    "#*************************************************************************************************************\n",
    "\n",
    "Copyright (c) 2020, Ankit Kariryaa\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.s\n",
    "\n",
    "#*************************************************************************************************************\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview \n",
    "The code was written by Ankit Kariryaa (Kariryaa AT uni-bremen DOT de) in 2018 (see https://doi.org/10.5281/zenodo.3978185), and some modifications were made by Jiawei Wei in 2022.\n",
    "\n",
    "Start by labeling a part of the satellite images with the surface thermal plumes and storing the labels in shapefiles. The areas that stand for the bounding box of background areas (circles) are denoted by the 'trainingArea', core surface thermal plumes in those areas are denoted by the 'trainingPolygon', mixed surface thermal plumes (background temperature plus 1 K) in those areas are denoted by the 'trainingPlus1'. \n",
    "\n",
    "First, we read the trainingArea, the trainingPolygon and trainingPlus1 from three separate shape files. Then we match the trainingArea, station name and trainingPlus1 for each trainingPolygon.\n",
    "\n",
    "Next, we read the raw satellite images (WST increment, Unit: K), and extract training image that overlap with a training area from each satellite image. The WST increment image that overlap with the training area and the corresponding label are then written to separate files.\n",
    "\n",
    "Finally, we calculated the Euclidean distance map (Eucl_dist_map) for each WST increment image and add Eucl_dist_map as a new channel to each WST increment image.\n",
    "\n",
    "Here, the term training area and training polygon represent all available input data, which can then be separated into training, validation, and test sets in the next notebook(s). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Create a new `notebooks/config/` directory by copying the `notebooks/configTemplate/` directory and define the paths to input and output data in the `notebooks/config/Preprocessing.py` file.  \n",
    "Note that in `notebooks/config/Preprocessing.py` you may need to change the default value of some variable (e.g., `raw_image_file_type` or `bands`) for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gps\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.mask\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "import rasterio.merge\n",
    "from rasterio.transform import rowcol\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import shapely\n",
    "from shapely.geometry import box, Point\n",
    "from shapely.ops import unary_union\n",
    "import pyproj                    # Change coordinate reference system\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import numpy as np               # numerical array manipulation\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw\n",
    "from core.visualize import display_images\n",
    "from core.frame_info import image_normalize\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/Preprocessing.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from config import Preprocessing_withLocation\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import Preprocessing\n",
    "\n",
    "config = Preprocessing_withLocation.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a total of 1952 object polygons and 7222 training areas and 7222 training plus1 masks\n",
      "Polygons will be assigned to training areas in the next steps.\n"
     ]
    }
   ],
   "source": [
    "#Read the training area, training polygons, plus1 \n",
    "trainingArea = gps.read_file(os.path.join(config.training_base_dir, config.training_area_fn))\n",
    "trainingPolygon = gps.read_file(os.path.join(config.training_base_dir, config.training_polygon_fn))\n",
    "trainingPlus1 = gps.read_file(os.path.join(config.training_base_dir, config.training_plus1_fn))\n",
    "\n",
    "print(f'Read a total of {trainingPolygon.shape[0]} object polygons and {trainingArea.shape[0]} training areas and {trainingPlus1.shape[0]} training plus1 masks')\n",
    "print(f'Polygons will be assigned to training areas in the next steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:4326\n",
      "epsg:4326\n",
      "epsg:4326\n"
     ]
    }
   ],
   "source": [
    "#Check if the training areas and the training polygons have the same crs\n",
    "if trainingArea.crs  != trainingPolygon.crs:\n",
    "    print('Training area CRS does not match training_polygon CRS')\n",
    "    targetCRS = trainingPolygon.crs #Areas are less in number so conversion should be faster\n",
    "    trainingArea = trainingArea.to_crs(targetCRS)\n",
    "print(trainingPolygon.crs)\n",
    "print(trainingArea.crs)\n",
    "print(trainingPlus1.crs)\n",
    "assert trainingPolygon.crs == trainingArea.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1952/1952 [00:00<00:00, 10901.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationNam</th>\n",
       "      <th>system_tim</th>\n",
       "      <th>id_info</th>\n",
       "      <th>system_t_1</th>\n",
       "      <th>system_t_2</th>\n",
       "      <th>system_t_3</th>\n",
       "      <th>system_t_4</th>\n",
       "      <th>system_t_5</th>\n",
       "      <th>system_t_6</th>\n",
       "      <th>system_t_7</th>\n",
       "      <th>...</th>\n",
       "      <th>system__68</th>\n",
       "      <th>system__69</th>\n",
       "      <th>system__70</th>\n",
       "      <th>system__71</th>\n",
       "      <th>system__72</th>\n",
       "      <th>system__73</th>\n",
       "      <th>system__74</th>\n",
       "      <th>system__75</th>\n",
       "      <th>geometry</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>LC08_121044_20130919</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>1.379559e+12</td>\n",
       "      <td>POLYGON ((114.49884 22.54688, 114.49884 22.668...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>LC08_121044_20131005</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>1.380941e+12</td>\n",
       "      <td>POLYGON ((114.49884 22.54688, 114.49884 22.668...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>LC08_121044_20141008</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>1.412736e+12</td>\n",
       "      <td>POLYGON ((114.49884 22.54688, 114.49884 22.668...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>LC08_121044_20141125</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>1.416884e+12</td>\n",
       "      <td>POLYGON ((114.49884 22.54688, 114.49884 22.668...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>LC08_121044_20150808</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>1.439002e+12</td>\n",
       "      <td>POLYGON ((114.49884 22.54688, 114.49884 22.668...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>LC08_020029_20180929</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>1.538238e+12</td>\n",
       "      <td>POLYGON ((-81.65838 44.28207, -81.65838 44.349...</td>\n",
       "      <td>7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>LC08_020029_20190527</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>1.558974e+12</td>\n",
       "      <td>POLYGON ((-81.65838 44.28207, -81.65838 44.349...</td>\n",
       "      <td>7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7219</th>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>LC08_020029_20190714</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>1.563121e+12</td>\n",
       "      <td>POLYGON ((-81.65838 44.28207, -81.65838 44.349...</td>\n",
       "      <td>7219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7220</th>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>LC08_020029_20200513</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>1.589387e+12</td>\n",
       "      <td>POLYGON ((-81.65838 44.28207, -81.65838 44.349...</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>LC08_020029_20200817</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>1.597681e+12</td>\n",
       "      <td>POLYGON ((-81.65838 44.28207, -81.65838 44.349...</td>\n",
       "      <td>7221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7222 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stationNam    system_tim               id_info    system_t_1  \\\n",
       "0     DayaBay-Lingao  1.379559e+12  LC08_121044_20130919  1.379559e+12   \n",
       "1     DayaBay-Lingao  1.380941e+12  LC08_121044_20131005  1.380941e+12   \n",
       "2     DayaBay-Lingao  1.412736e+12  LC08_121044_20141008  1.412736e+12   \n",
       "3     DayaBay-Lingao  1.416884e+12  LC08_121044_20141125  1.416884e+12   \n",
       "4     DayaBay-Lingao  1.439002e+12  LC08_121044_20150808  1.439002e+12   \n",
       "...              ...           ...                   ...           ...   \n",
       "7217         Bruce_2  1.538238e+12  LC08_020029_20180929  1.538238e+12   \n",
       "7218         Bruce_2  1.558974e+12  LC08_020029_20190527  1.558974e+12   \n",
       "7219         Bruce_2  1.563121e+12  LC08_020029_20190714  1.563121e+12   \n",
       "7220         Bruce_2  1.589387e+12  LC08_020029_20200513  1.589387e+12   \n",
       "7221         Bruce_2  1.597681e+12  LC08_020029_20200817  1.597681e+12   \n",
       "\n",
       "        system_t_2    system_t_3    system_t_4    system_t_5    system_t_6  \\\n",
       "0     1.379559e+12  1.379559e+12  1.379559e+12  1.379559e+12  1.379559e+12   \n",
       "1     1.380941e+12  1.380941e+12  1.380941e+12  1.380941e+12  1.380941e+12   \n",
       "2     1.412736e+12  1.412736e+12  1.412736e+12  1.412736e+12  1.412736e+12   \n",
       "3     1.416884e+12  1.416884e+12  1.416884e+12  1.416884e+12  1.416884e+12   \n",
       "4     1.439002e+12  1.439002e+12  1.439002e+12  1.439002e+12  1.439002e+12   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "7217  1.538238e+12  1.538238e+12  1.538238e+12  1.538238e+12  1.538238e+12   \n",
       "7218  1.558974e+12  1.558974e+12  1.558974e+12  1.558974e+12  1.558974e+12   \n",
       "7219  1.563121e+12  1.563121e+12  1.563121e+12  1.563121e+12  1.563121e+12   \n",
       "7220  1.589387e+12  1.589387e+12  1.589387e+12  1.589387e+12  1.589387e+12   \n",
       "7221  1.597681e+12  1.597681e+12  1.597681e+12  1.597681e+12  1.597681e+12   \n",
       "\n",
       "        system_t_7  ...    system__68    system__69    system__70  \\\n",
       "0     1.379559e+12  ...  1.379559e+12  1.379559e+12  1.379559e+12   \n",
       "1     1.380941e+12  ...  1.380941e+12  1.380941e+12  1.380941e+12   \n",
       "2     1.412736e+12  ...  1.412736e+12  1.412736e+12  1.412736e+12   \n",
       "3     1.416884e+12  ...  1.416884e+12  1.416884e+12  1.416884e+12   \n",
       "4     1.439002e+12  ...  1.439002e+12  1.439002e+12  1.439002e+12   \n",
       "...            ...  ...           ...           ...           ...   \n",
       "7217  1.538238e+12  ...  1.538238e+12  1.538238e+12  1.538238e+12   \n",
       "7218  1.558974e+12  ...  1.558974e+12  1.558974e+12  1.558974e+12   \n",
       "7219  1.563121e+12  ...  1.563121e+12  1.563121e+12  1.563121e+12   \n",
       "7220  1.589387e+12  ...  1.589387e+12  1.589387e+12  1.589387e+12   \n",
       "7221  1.597681e+12  ...  1.597681e+12  1.597681e+12  1.597681e+12   \n",
       "\n",
       "        system__71    system__72    system__73    system__74    system__75  \\\n",
       "0     1.379559e+12  1.379559e+12  1.379559e+12  1.379559e+12  1.379559e+12   \n",
       "1     1.380941e+12  1.380941e+12  1.380941e+12  1.380941e+12  1.380941e+12   \n",
       "2     1.412736e+12  1.412736e+12  1.412736e+12  1.412736e+12  1.412736e+12   \n",
       "3     1.416884e+12  1.416884e+12  1.416884e+12  1.416884e+12  1.416884e+12   \n",
       "4     1.439002e+12  1.439002e+12  1.439002e+12  1.439002e+12  1.439002e+12   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "7217  1.538238e+12  1.538238e+12  1.538238e+12  1.538238e+12  1.538238e+12   \n",
       "7218  1.558974e+12  1.558974e+12  1.558974e+12  1.558974e+12  1.558974e+12   \n",
       "7219  1.563121e+12  1.563121e+12  1.563121e+12  1.563121e+12  1.563121e+12   \n",
       "7220  1.589387e+12  1.589387e+12  1.589387e+12  1.589387e+12  1.589387e+12   \n",
       "7221  1.597681e+12  1.597681e+12  1.597681e+12  1.597681e+12  1.597681e+12   \n",
       "\n",
       "                                               geometry  order  \n",
       "0     POLYGON ((114.49884 22.54688, 114.49884 22.668...      0  \n",
       "1     POLYGON ((114.49884 22.54688, 114.49884 22.668...      1  \n",
       "2     POLYGON ((114.49884 22.54688, 114.49884 22.668...      2  \n",
       "3     POLYGON ((114.49884 22.54688, 114.49884 22.668...      3  \n",
       "4     POLYGON ((114.49884 22.54688, 114.49884 22.668...      4  \n",
       "...                                                 ...    ...  \n",
       "7217  POLYGON ((-81.65838 44.28207, -81.65838 44.349...   7217  \n",
       "7218  POLYGON ((-81.65838 44.28207, -81.65838 44.349...   7218  \n",
       "7219  POLYGON ((-81.65838 44.28207, -81.65838 44.349...   7219  \n",
       "7220  POLYGON ((-81.65838 44.28207, -81.65838 44.349...   7220  \n",
       "7221  POLYGON ((-81.65838 44.28207, -81.65838 44.349...   7221  \n",
       "\n",
       "[7222 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allNullFla</th>\n",
       "      <th>areaFlag</th>\n",
       "      <th>stationNam</th>\n",
       "      <th>areaLimit_</th>\n",
       "      <th>core_area</th>\n",
       "      <th>type</th>\n",
       "      <th>id_info</th>\n",
       "      <th>geometry</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>1.512857e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20130919</td>\n",
       "      <td>POLYGON ((114.55684 22.59996, 114.55683 22.600...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>4.555738e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20131005</td>\n",
       "      <td>POLYGON ((114.56597 22.59468, 114.56597 22.594...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>4.728839e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20141008</td>\n",
       "      <td>POLYGON ((114.58627 22.60149, 114.58628 22.600...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>4.802820e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20141125</td>\n",
       "      <td>POLYGON ((114.55912 22.60270, 114.55911 22.603...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>8.299121e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20150808</td>\n",
       "      <td>POLYGON ((114.57430 22.58533, 114.57428 22.586...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.683838e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20180929</td>\n",
       "      <td>POLYGON ((-81.61398 44.31402, -81.61398 44.314...</td>\n",
       "      <td>7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.781353e+05</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20190527</td>\n",
       "      <td>POLYGON ((-81.61584 44.31158, -81.61584 44.311...</td>\n",
       "      <td>7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7219</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.258333e+04</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20190714</td>\n",
       "      <td>POLYGON ((-81.61211 44.31538, -81.61212 44.315...</td>\n",
       "      <td>7219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.453743e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20200513</td>\n",
       "      <td>POLYGON ((-81.61512 44.31510, -81.61512 44.315...</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.806077e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20200817</td>\n",
       "      <td>POLYGON ((-81.61205 44.30944, -81.61205 44.309...</td>\n",
       "      <td>7221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7222 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      allNullFla  areaFlag      stationNam  areaLimit_     core_area     type  \\\n",
       "0              0         1  DayaBay-Lingao           1  1.512857e+06  Polygon   \n",
       "1              0         0  DayaBay-Lingao           1  4.555738e+06  Polygon   \n",
       "2              0         0  DayaBay-Lingao           1  4.728839e+06  Polygon   \n",
       "3              0         0  DayaBay-Lingao           1  4.802820e+06  Polygon   \n",
       "4              0         0  DayaBay-Lingao           1  8.299121e+06  Polygon   \n",
       "...          ...       ...             ...         ...           ...      ...   \n",
       "7217           0         0         Bruce_2           1  2.683838e+06  Polygon   \n",
       "7218           0         1         Bruce_2           1  8.781353e+05  Polygon   \n",
       "7219           0         1         Bruce_2           1  1.258333e+04  Polygon   \n",
       "7220           0         0         Bruce_2           1  2.453743e+06  Polygon   \n",
       "7221           0         0         Bruce_2           1  2.806077e+06  Polygon   \n",
       "\n",
       "                   id_info                                           geometry  \\\n",
       "0     LC08_121044_20130919  POLYGON ((114.55684 22.59996, 114.55683 22.600...   \n",
       "1     LC08_121044_20131005  POLYGON ((114.56597 22.59468, 114.56597 22.594...   \n",
       "2     LC08_121044_20141008  POLYGON ((114.58627 22.60149, 114.58628 22.600...   \n",
       "3     LC08_121044_20141125  POLYGON ((114.55912 22.60270, 114.55911 22.603...   \n",
       "4     LC08_121044_20150808  POLYGON ((114.57430 22.58533, 114.57428 22.586...   \n",
       "...                    ...                                                ...   \n",
       "7217  LC08_020029_20180929  POLYGON ((-81.61398 44.31402, -81.61398 44.314...   \n",
       "7218  LC08_020029_20190527  POLYGON ((-81.61584 44.31158, -81.61584 44.311...   \n",
       "7219  LC08_020029_20190714  POLYGON ((-81.61211 44.31538, -81.61212 44.315...   \n",
       "7220  LC08_020029_20200513  POLYGON ((-81.61512 44.31510, -81.61512 44.315...   \n",
       "7221  LC08_020029_20200817  POLYGON ((-81.61205 44.30944, -81.61205 44.309...   \n",
       "\n",
       "      order  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  \n",
       "...     ...  \n",
       "7217   7217  \n",
       "7218   7218  \n",
       "7219   7219  \n",
       "7220   7220  \n",
       "7221   7221  \n",
       "\n",
       "[7222 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allNullFla</th>\n",
       "      <th>areaFlag</th>\n",
       "      <th>stationNam</th>\n",
       "      <th>areaLimit_</th>\n",
       "      <th>core_area</th>\n",
       "      <th>type</th>\n",
       "      <th>id_info</th>\n",
       "      <th>geometry</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>2.327901e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20131005</td>\n",
       "      <td>POLYGON ((114.56209 22.59977, 114.56208 22.600...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>2.297242e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20141008</td>\n",
       "      <td>POLYGON ((114.57523 22.59915, 114.57522 22.599...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>2.119652e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20141125</td>\n",
       "      <td>POLYGON ((114.56257 22.60573, 114.56254 22.607...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>5.031753e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20150808</td>\n",
       "      <td>POLYGON ((114.57910 22.59434, 114.57912 22.593...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DayaBay-Lingao</td>\n",
       "      <td>1</td>\n",
       "      <td>3.765099e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_121044_20160607</td>\n",
       "      <td>POLYGON ((114.60302 22.62828, 114.60303 22.627...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.015040e+05</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20180929</td>\n",
       "      <td>POLYGON ((-81.61361 44.31430, -81.61361 44.314...</td>\n",
       "      <td>1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.338921e+05</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20190527</td>\n",
       "      <td>POLYGON ((-81.61961 44.31237, -81.61961 44.312...</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.258333e+04</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20190714</td>\n",
       "      <td>POLYGON ((-81.61211 44.31538, -81.61212 44.315...</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.876710e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20200513</td>\n",
       "      <td>POLYGON ((-81.61286 44.31511, -81.61287 44.315...</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.302373e+06</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>LC08_020029_20200817</td>\n",
       "      <td>POLYGON ((-81.61169 44.31106, -81.61170 44.311...</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1952 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      allNullFla  areaFlag      stationNam  areaLimit_     core_area     type  \\\n",
       "0              0         0  DayaBay-Lingao           1  2.327901e+06  Polygon   \n",
       "1              0         0  DayaBay-Lingao           1  2.297242e+06  Polygon   \n",
       "2              0         0  DayaBay-Lingao           1  2.119652e+06  Polygon   \n",
       "3              0         0  DayaBay-Lingao           1  5.031753e+06  Polygon   \n",
       "4              0         0  DayaBay-Lingao           1  3.765099e+06  Polygon   \n",
       "...          ...       ...             ...         ...           ...      ...   \n",
       "1947           0         1         Bruce_2           1  9.015040e+05  Polygon   \n",
       "1948           0         1         Bruce_2           1  5.338921e+05  Polygon   \n",
       "1949           0         1         Bruce_2           1  1.258333e+04  Polygon   \n",
       "1950           0         1         Bruce_2           1  1.876710e+06  Polygon   \n",
       "1951           0         1         Bruce_2           1  1.302373e+06  Polygon   \n",
       "\n",
       "                   id_info                                           geometry  \\\n",
       "0     LC08_121044_20131005  POLYGON ((114.56209 22.59977, 114.56208 22.600...   \n",
       "1     LC08_121044_20141008  POLYGON ((114.57523 22.59915, 114.57522 22.599...   \n",
       "2     LC08_121044_20141125  POLYGON ((114.56257 22.60573, 114.56254 22.607...   \n",
       "3     LC08_121044_20150808  POLYGON ((114.57910 22.59434, 114.57912 22.593...   \n",
       "4     LC08_121044_20160607  POLYGON ((114.60302 22.62828, 114.60303 22.627...   \n",
       "...                    ...                                                ...   \n",
       "1947  LC08_020029_20180929  POLYGON ((-81.61361 44.31430, -81.61361 44.314...   \n",
       "1948  LC08_020029_20190527  POLYGON ((-81.61961 44.31237, -81.61961 44.312...   \n",
       "1949  LC08_020029_20190714  POLYGON ((-81.61211 44.31538, -81.61212 44.315...   \n",
       "1950  LC08_020029_20200513  POLYGON ((-81.61286 44.31511, -81.61287 44.315...   \n",
       "1951  LC08_020029_20200817  POLYGON ((-81.61169 44.31106, -81.61170 44.311...   \n",
       "\n",
       "      order  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  \n",
       "...     ...  \n",
       "1947   1947  \n",
       "1948   1948  \n",
       "1949   1949  \n",
       "1950   1950  \n",
       "1951   1951  \n",
       "\n",
       "[1952 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tqdm(trainingPolygon.index): \n",
    "    if trainingPolygon.loc[i]['geometry'].geom_type=='MultiPolygon':\n",
    "        unary_union(trainingPolygon.loc[i]['geometry'])\n",
    "# Assign serial order to training areas\n",
    "trainingArea['order'] = range(trainingArea.shape[0])\n",
    "trainingArea\n",
    "\n",
    "# Assign serial order to training plus1 masks\n",
    "trainingPlus1['order'] = range(trainingPlus1.shape[0])\n",
    "trainingPlus1\n",
    "\n",
    "# Assign serial order to training polygons\n",
    "trainingPolygon['order'] = range(trainingPolygon.shape[0])\n",
    "trainingPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name      Lat       Lon Location  Radius Drainage  \\\n",
      "0   DayaBay-Lingao  22.6076  114.5641      Bay     225  Shallow   \n",
      "1        Yangjiang  21.7024  112.2713     Open      75     Deep   \n",
      "2       Changjiang  19.4737  108.8834     Open     175     Deep   \n",
      "3           Fuqing  25.4152  119.4365      Bay     125  Shallow   \n",
      "4           Ningde  27.0524  120.2868      Bay     275  Shallow   \n",
      "..             ...      ...       ...      ...     ...      ...   \n",
      "69     Point_Beach  44.2822  -87.5327     Lake     175  Shallow   \n",
      "70  Robert_E_Ginna  43.2805  -77.3082     Lake     125  Shallow   \n",
      "71            Zion  42.4450  -87.7982     Lake     125     Deep   \n",
      "72         Bruce_1  44.3448  -81.5784     Lake     275  Shallow   \n",
      "73         Bruce_2  44.3158  -81.6116     Lake     125  Shallow   \n",
      "\n",
      "          Country         Region  Capacity Start_date   End_date        CP1  \\\n",
      "0           China      East Asia      5802 2002-02-26        NaT 2002-12-15   \n",
      "1           China      East Asia      6000 2013-12-31        NaT 2015-03-10   \n",
      "2           China      East Asia      1202 2015-11-07        NaT 2016-06-20   \n",
      "3           China      East Asia      5000 2014-08-20        NaT 2015-08-06   \n",
      "4           China      East Asia      4072 2012-12-28        NaT 2014-01-04   \n",
      "..            ...            ...       ...        ...        ...        ...   \n",
      "69  United States  North America      1182 1970-11-06        NaT 1972-08-02   \n",
      "70  United States  North America       560 1969-12-02        NaT        NaT   \n",
      "71  United States  North America      2080 1973-06-28 1998-02-13 1973-12-26   \n",
      "72         Canada  North America      6358 1977-01-14        NaT 1976-09-04   \n",
      "73         Canada  North America      6358 1977-01-14        NaT 1976-09-04   \n",
      "\n",
      "          CP2        CP3        CP4        CP5        CP6        CP7 CP8  \n",
      "0  2010-07-15 2011-05-03        NaT        NaT        NaT        NaT NaT  \n",
      "1  2015-10-18 2017-01-08 2018-05-23 2019-06-29        NaT        NaT NaT  \n",
      "2         NaT        NaT        NaT        NaT        NaT        NaT NaT  \n",
      "3  2016-09-07 2017-07-29 2020-11-27        NaT        NaT        NaT NaT  \n",
      "4  2015-03-21 2016-03-29        NaT        NaT        NaT        NaT NaT  \n",
      "..        ...        ...        ...        ...        ...        ...  ..  \n",
      "69        NaT        NaT        NaT        NaT        NaT        NaT NaT  \n",
      "70        NaT        NaT        NaT        NaT        NaT        NaT NaT  \n",
      "71 1998-02-13        NaT        NaT        NaT        NaT        NaT NaT  \n",
      "72 1977-12-12 1978-12-21 1984-12-02 1984-06-26 1986-02-22 1987-03-09 NaT  \n",
      "73 1977-12-12 1978-12-21 1984-12-02 1984-06-26 1986-02-22 1987-03-09 NaT  \n",
      "\n",
      "[74 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# read outlets location\n",
    "df_info = pd.read_excel(r'I:\\results\\SST\\landsat\\location.xlsx', engine='openpyxl')\n",
    "print(df_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7222/7222 [50:52<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned training polygons in 1952 training areas and created weighted boundaries for polygons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# As input we received three shapefiles, trainingArea contains the training areas/rectangles,\n",
    "# trainingPolygon contains the polygon of core surface thermal plumes in those training areas,\n",
    "# trainingPlus1 contains the polygon of mixed surface thermal plumes in those training areas.\n",
    "# The first task is to determine the parent training area for each polygon/plus1 polygon.\n",
    "\n",
    "def dividePolygonsInTrainingAreas(trainingPolygon, trainingArea, trainingPlus1):\n",
    "    '''\n",
    "    Assign annotated ploygons in to the training areas.\n",
    "    '''\n",
    "    # For efficiency, assigned polygons are removed from the list, we make a copy here. \n",
    "    cpTrainingPolygon = trainingPolygon.copy()\n",
    "    cpTrainingPlus1 = trainingPlus1.copy()\n",
    "    splitPolygons = {}\n",
    "    for i in tqdm(trainingArea.index):\n",
    "        spTemp = []\n",
    "        allocated_j = []\n",
    "        for j in cpTrainingPolygon.index:\n",
    "            if (trainingArea.loc[i]['id_info']==cpTrainingPolygon.loc[j]['id_info']) and (trainingArea.loc[i]['stationNam']==cpTrainingPolygon.loc[j]['stationNam']):  \n",
    "                spTemp.append(cpTrainingPolygon.loc[j])\n",
    "                allocated_j.append(j)\n",
    "                allocated_k = []\n",
    "                for k in cpTrainingPlus1.index:\n",
    "                    if (cpTrainingPolygon.loc[j]['id_info']==cpTrainingPlus1.loc[k]['id_info']) and (cpTrainingPolygon.loc[j]['stationNam']==cpTrainingPlus1.loc[k]['stationNam']):\n",
    "                        splitPolygons[cpTrainingPolygon.loc[j]['order']] = {'polygons':spTemp, 'bounds':list(trainingArea.bounds.loc[i]), 'id':trainingArea.loc[i]['id_info'], 'stationName':trainingArea.loc[i]['stationNam'], 'plus1':[cpTrainingPlus1.loc[k]]} \n",
    "                        allocated_k.append(k)\n",
    "                        cpTrainingPlus1 = cpTrainingPlus1.drop(allocated_k)\n",
    "                        break\n",
    "                cpTrainingPolygon = cpTrainingPolygon.drop(allocated_j) #narraw search range \n",
    "                break\n",
    "    return splitPolygons\n",
    "\n",
    "# areasWithPolygons contains the object polygons for each area!\n",
    "areasWithPolygons = dividePolygonsInTrainingAreas(trainingPolygon, trainingArea, trainingPlus1)\n",
    "# print(areasWithPolygons)\n",
    "print(f'Assigned training polygons in {len(areasWithPolygons)} training areas for polygons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 7222 pair of raw image(s) to process!\n"
     ]
    }
   ],
   "source": [
    "# Read the raw input images\n",
    "def readInputImages(imageBaseDir, rawImageFileType, rawWSTImagePrefix):\n",
    "    \"\"\"\n",
    "    Reads all images with prefix WST_image_prefix and image_file_type datatype in the image_base_dir directory.\n",
    "    \"\"\"     \n",
    "    \n",
    "    WSTImageFn = []\n",
    "    for root, dirs, files in os.walk(imageBaseDir):\n",
    "        for file in files:\n",
    "#             print(os.path.join(root, file))\n",
    "#             if file.endswith(rawImageFileType) and file.startswith(rawWSTImagePrefix):\n",
    "            WSTImageFn.append(os.path.join(root, file))\n",
    "    inputImages = list(WSTImageFn)\n",
    "    return inputImages\n",
    "\n",
    "inputImages = readInputImages(config.raw_image_base_dir, config.raw_image_file_type, config.raw_WST_image_prefix)\n",
    "print(f'Found a total of {len(inputImages)} pair of raw image(s) to process!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each raw satellite image, determine if it overlaps with a training area. \n",
    "# If a overlap if found, then extract + write the overlapping part of the raw image, create + write an image from training polygons.\n",
    "\n",
    "def drawPolygons(polygons, shape, outline, fill):\n",
    "    \"\"\"\n",
    "    From the polygons, create a numpy mask with fill value in the foreground and 0 value in the background.\n",
    "    Outline (i.e the edge of the polygon) can be assigned a separate value.\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "\n",
    "    for polygon in polygons:\n",
    "        xy = [(point[1], point[0]) for point in polygon]\n",
    "        draw.polygon(xy=xy, outline=outline, fill=fill)\n",
    "    mask = np.array(mask)#, dtype=bool)\n",
    "    return(mask)\n",
    "\n",
    "\n",
    "def rowColPolygons(areaDf, areaShape, profile, filename, outline, fill):\n",
    "    \"\"\"\n",
    "    Convert polygons coordinates to image pixel coordinates, create annotation image using drawPolygons() and write the results into an image file.\n",
    "    \"\"\"\n",
    "    transform = profile['transform']\n",
    "    polygons = []\n",
    "    for i in areaDf.index:\n",
    "        gm = areaDf.loc[i]['geometry']\n",
    "        a,b = zip(*list(gm.exterior.coords))\n",
    "        row, col = rasterio.transform.rowcol(transform, a, b)\n",
    "        zipped = list(zip(row,col)) #[list(rc) for rc in list(zip(row,col))]\n",
    "        polygons.append(zipped)\n",
    "    with open(filename, 'w') as outfile:  \n",
    "        json.dump({'Plumes': polygons}, outfile)\n",
    "    mask = drawPolygons(polygons,areaShape, outline=outline, fill=fill)\n",
    "    profile['dtype'] = rasterio.int16\n",
    "    profile_ann = profile.copy()\n",
    "    profile_ann['count'] = 1\n",
    "    with rasterio.open(filename.replace('json', 'tif'), 'w', **profile_ann) as dst:\n",
    "        dst.write(mask.astype(rasterio.int16), 1)\n",
    "    return(mask.astype(rasterio.int16))\n",
    "\n",
    "def rowColPolygons_plus1(areaDf, areaShape, profile, filename, outline, fill):\n",
    "    \"\"\"\n",
    "    Convert polygons coordinates to image pixel coordinates, create annotation image using drawPolygons() and write the results into an image file.\n",
    "    \"\"\"\n",
    "    transform = profile['transform']\n",
    "    polygons = []\n",
    "    for i in areaDf.index:\n",
    "        gm = areaDf.loc[i]['geometry']\n",
    "        a,b = zip(*list(gm.exterior.coords))\n",
    "        row, col = rasterio.transform.rowcol(transform, a, b)\n",
    "        zipped = list(zip(row,col)) #[list(rc) for rc in list(zip(row,col))]\n",
    "        polygons.append(zipped)\n",
    "#     with open(filename, 'w') as outfile:  \n",
    "#         json.dump({'Plumes': polygons}, outfile)\n",
    "    mask = drawPolygons(polygons,areaShape, outline=outline, fill=fill)\n",
    "    return(mask.astype(rasterio.int16))\n",
    "\n",
    "def writeExtractedImageAndAnnotation(img, sm, Eucl_dist_map, profile, idImgStation, idImgDate, idImg, polygonsInAreaDf, plus1Mask, writePath, imagesFilename, annotationFilename, bands, writeCounter, writeCounter_hard, normalize=False):# boundariesInAreaDf, boundaryFilename, \n",
    "    \"\"\"\n",
    "    Write the part of raw image that overlaps with a training area into a separate image file. \n",
    "    Use rowColPolygons to create and write annotation and boundary image from polygons in the training area.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        writePath_hard = r'I:\\results\\SST\\landsat\\extractWithLocation\\extract50_hard_withLocation'\n",
    "        if annotationFilename:\n",
    "            annotation_json_filepath = os.path.join(writePath,annotationFilename+'_{}_'.format(writeCounter)+idImgStation+'_'+idImg+'.json')\n",
    "            annotation_json_filepath_hard = os.path.join(writePath_hard,annotationFilename+'_{}_'.format(writeCounter_hard)+idImgStation+'_'+idImg+'.json')\n",
    "            # The object is given a value of 1, the outline or the border of the object is given a value of 0 and rest of the image/background is given a a value of 0\n",
    "#             mask = rowColPolygons(polygonsInAreaDf,(sm[0].shape[1], sm[0].shape[2]), profile, annotation_json_filepath, outline=1, fill = 1) \n",
    "            mask_plus1 = rowColPolygons_plus1(plus1Mask,(sm[0].shape[1], sm[0].shape[2]), profile, annotation_json_filepath, outline=1, fill = 1) \n",
    "        for band, imFn in zip(bands, imagesFilename):\n",
    "            # Rasterio reads file channel first, so the sm[0] has the shape [1 or ch_count, x,y]\n",
    "            # If raster has multiple channels, then bands will be [0, 1, ...] otherwise simply [0]\n",
    "            profile['dtype'] = rasterio.float32\n",
    "            dt = sm[0][band].astype(profile['dtype']) \n",
    "            dt_ls = [dt, Eucl_dist_map]\n",
    "            profile['count'] = 2\n",
    "            \n",
    "            #mask outside of plus1 \n",
    "            dt[mask_plus1==0] = np.nan\n",
    "            Eucl_dist_map[mask_plus1==0] = np.nan\n",
    "                        \n",
    "            #mask abnormal value (manual inspection)\n",
    "            if idImgStation == 'Takahama':\n",
    "                dt[dt>=10] = np.nan\n",
    "            if idImgStation == 'Ohi':\n",
    "                dt[dt>=10] = np.nan\n",
    "       \n",
    "            \n",
    "            if normalize: # Note: If the raster contains None values, then you should normalize it separately by calculating the mean and std without those values.\n",
    "                dt = image_normalize(dt, axis=None) #  Normalize the image along the width and height, and since here we only have one channel we pass axis as None          \n",
    "            with rasterio.open(os.path.join(writePath, imFn+'_{}_'.format(writeCounter)+idImgStation+'_'+idImg+'.tif'), 'w', **profile) as dst: \n",
    "                    for band_id, src in enumerate(dt_ls, start=1):\n",
    "                        dst.write(src, band_id)\n",
    "            # mask = rowColPolygons(polygonsInAreaDf,(sm[0].shape[1], sm[0].shape[2]), profile, annotation_json_filepath, outline=1, fill = 1) \n",
    "        return(writeCounter+1, writeCounter_hard)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Something nasty happened, could not write the annotation or the mask file!\")\n",
    "        return writeCounter, writeCounter_hard\n",
    "        \n",
    "        \n",
    "def findOverlap(img, areasWithPolygons, writePath, imageFilename, annotationFilename, bands, writeCounter=1, writeCounter_hard=1):\n",
    "    \"\"\"\n",
    "    Finds overlap of image with a training area.\n",
    "    Use writeExtractedImageAndAnnotation() to write the overlapping training area and corresponding polygons in separate image files.\n",
    "    \"\"\"\n",
    "    overlapppedAreas = set()\n",
    "    for areaID, areaInfo in areasWithPolygons.items():                                 \n",
    "        #Convert the polygons in the area in a dataframe and get the bounds of the area. \n",
    "        polygonsInAreaDf = gps.GeoDataFrame(areaInfo['polygons'])\n",
    "        plus1Mask = gps.GeoDataFrame(areaInfo['plus1'])\n",
    "        idArea_sub = areaInfo['id'].find('L')\n",
    "        idArea = areaInfo['id'][idArea_sub:]\n",
    "        idAreaStation = areaInfo['stationName']\n",
    "        \n",
    "        idImg_sub = img.name.rfind('L')\n",
    "        idImg = img.name[idImg_sub:-4]\n",
    "        idImgDate = img.name[idImg_sub+12:-4]\n",
    "        idImgStation_sub = img.name.find('_')\n",
    "        idImgStation = img.name[idImgStation_sub+1:idImg_sub-1]\n",
    "        \n",
    "        #test whether image is included in df_info\n",
    "        t = df_info.loc[df_info['Name']==idImgStation, ['Lon']]\n",
    "        if t.empty:\n",
    "            print('Empty!'+idImgStation)\n",
    "            break\n",
    "        \n",
    "        bboxArea = box(*areaInfo['bounds'])\n",
    "        bboxImg = box(*img.bounds)\n",
    "        #Extract the window if area is in the image\n",
    "        if idArea==idImg and idAreaStation==idImgStation: \n",
    "            profile = img.profile  \n",
    "            sm = rasterio.mask.mask(img, [bboxArea], all_touched=True, crop=True )\n",
    "            profile['height'] = sm[0].shape[1]\n",
    "            profile['width'] = sm[0].shape[2]\n",
    "            profile['transform'] = sm[1]   \n",
    "            # That's a problem with rasterio, if the height and the width are less then 256 it throws: ValueError: blockysize exceeds raster height \n",
    "            # So I set the blockxsize and blockysize to prevent this problem\n",
    "            profile['blockxsize'] = 32 \n",
    "            profile['blockysize'] = 32\n",
    "            profile['count'] = 1\n",
    "            profile['dtype'] = rasterio.float32\n",
    "            \n",
    "            #obtain the lat lon for each outlet (ol), calcualate the Euclidean distance map\n",
    "            lat = df_info.loc[df_info['Name']==idImgStation, ['Lat']].iloc[0, 0]\n",
    "            lon = df_info.loc[df_info['Name']==idImgStation, ['Lon']].iloc[0, 0]\n",
    "            transform = profile['transform']\n",
    "            row_ol, col_ol = rasterio.transform.rowcol(transform, lon, lat)\n",
    "            row_num = profile['height'] \n",
    "            col_num = profile['width']\n",
    "            row_ol_map = np.ones((row_num, col_num))*row_ol\n",
    "            col_ol_map = np.ones((row_num, col_num))*col_ol\n",
    "\n",
    "            row_map = np.tile(np.arange(0, row_num).reshape(row_num, 1), (1, col_num))\n",
    "            col_map = np.tile(np.arange(0, col_num), (row_num, 1))\n",
    "            Eucl_dist_map = np.power((np.power((row_map-row_ol_map), 2) + np.power((col_map-col_ol_map), 2)), 0.5).astype(profile['dtype'])\n",
    "\n",
    "            \n",
    "            # writeExtractedImageAndAnnotation writes the image, annotation and boundaries and returns the counter of the next file to write. \n",
    "            writeCounter, writeCounter_hard = writeExtractedImageAndAnnotation(img, sm, Eucl_dist_map, profile, idImgStation, idImgDate, idImg, polygonsInAreaDf, plus1Mask, writePath, imageFilename, annotationFilename, bands, writeCounter, writeCounter_hard)#boundariesInAreaDf, boundaryFilename, \n",
    "            print(idImgStation+'_'+idImg)\n",
    "            overlapppedAreas.add(areaID)\n",
    "            areasWithPolygons.pop(areaID)\n",
    "            break\n",
    "    return(writeCounter, writeCounter_hard, overlapppedAreas)\n",
    "\n",
    "\n",
    "def extractAreasThatOverlapWithTrainingData(inputImages, areasWithPolygons, writePath, WSTFilename, annotationFilename, bands, writeCounter, writeCounter_hard):\n",
    "    \"\"\"\n",
    "    Iterates over raw WST image and using findOverlap() extract areas that overlap with training data. The overlapping areas in raw images are written in a separate file, and annotation and boundary file are created from polygons in the overlapping areas.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(writePath):\n",
    "        os.makedirs(writePath)\n",
    "        \n",
    "    overlapppedAreas = set()\n",
    "    cpAreasWithPolygons = areasWithPolygons.copy()\n",
    "    for imgs in tqdm(inputImages):\n",
    "        WSTImg = rasterio.open(imgs, 'r+')\n",
    "\n",
    "        ncWST, ncWST_hard, imOverlapppedAreasWST = findOverlap(WSTImg, cpAreasWithPolygons, writePath=writePath, imageFilename=[WSTFilename], annotationFilename=annotationFilename, bands=bands, writeCounter=writeCounter, writeCounter_hard=writeCounter_hard)#boundaryFilename=boundaryFilename, \n",
    "        \n",
    "        writeCounter = ncWST\n",
    "        writeCounter_hard = ncWST_hard\n",
    "\n",
    "        if overlapppedAreas.intersection(imOverlapppedAreasWST):\n",
    "            print(f'Information: Training area(s) {overlapppedAreas.intersection(imOverlapppedAreasWST)} spans over multiple raw images. This is common and expected in many cases. A part was found to overlap with current input image.')\n",
    "        overlapppedAreas.update(imOverlapppedAreasWST)\n",
    "    \n",
    "    allAreas = set(areasWithPolygons.keys())\n",
    "    if allAreas.difference(overlapppedAreas):\n",
    "        print(f'Warning: Could not find a raw image correspoinding to {allAreas.difference(overlapppedAreas)} areas. Make sure that you have provided the correct paths!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the main function for extracting part of WST images that overlap with training areas\n",
    "writeCounter=481\n",
    "writeCounter_hard=0\n",
    "extractAreasThatOverlapWithTrainingData(inputImages, areasWithPolygons, config.path_to_write, config.extracted_WST_filename, config.extracted_annotation_filename, config.bands, writeCounter, writeCounter_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Display extracted image\n",
    "sampleImage = '_1.png'\n",
    "fn = os.path.join(config.path_to_write, config.extracted_WST_filename + sampleImage )\n",
    "\n",
    "WST_img = Image.open(fn)\n",
    "read_WST_img = np.array(WST_img)\n",
    "annotation_im = Image.open(fn.replace(config.extracted_WST_filename ,config.extracted_annotation_filename))\n",
    "read_annotation = np.array(annotation_im)\n",
    "all_images = np.array([read_WST_img, read_annotation])\n",
    "display_images(np.expand_dims(np.transpose(all_images, axes=(1,2,0)), axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
