# GCNT-Plume: Long-term observation of global nuclear power plants thermal plumes using Landsat images and deep learning
This repository contains the neural network model (UNet) and other essential codes for segmenting nuclear power plants along global coasts and the Great Lakes. The code was written by Ankit Kariryaa (Kariryaa AT uni-bremen DOT de) in 2018, and some modifications were made by Jiawei Wei in 2022. Please contact Wei if you have any question.(email: 11930291@mail.sustech.edu.cn)

## Setup and Installation
See [INSTALL]

## Structure of the model
The code is structured in Jupyter notebooks available in the noteooks/ folder. Each notebook contains a considerable part of the pipeline and they are supported with core libraries available in the notebooks/core directory. Input, output paths and other configurations for each notebook must be declared in the notebooks/config/ directory. Please follow these three steps for training a UNet model and for mapping surface thermal plumes using the trained UNet model.

## Overall description of data
The WST increment images in the “**delta**” folder, named “**delta_StationName_ImageName.tif**”, are utilized for extracting mixed areas and core areas using threshold segmentation methods. The prepared mixed areas are saved as “**delta_index_StationName_ImageName.tif**” in the “**extractWithLocation**” folder, while the core areas are saved as “**annotation_index_StationName_ImageName.tif**” in the same folder. It should be noted that the values in the “**delta_index_StationName_ImageName.tif**” files represent WST increments, and the “**annotation_index_StationName_ImageName.tif**” files are binary images where a value of 1 indicates the extent of core areas. Furthermore, the Euclidean distance to the drainage outlet is included as an additional band in the “**delta_index_StationName_ImageName.tif**” files within the “**extractWithLocation**” folder. To provide these data in a more convenient way, we aggregated the .tif data to generate polygons in the form of shapefiles. The mixed area polygons are saved as “**plus1_all.shp**” in the “**sampleAnnotation(50\75)**” folders, and the corresponding core area polygons are saved as “**train(5\75)_all.shp**” in the same folders. Both the mixed area and core area polygons are determined within the background area, which is represented by the “**area_all.shp**” file in the “**sampleAnnotation(50\75)**” folders. It is in fact an external rectangle that encompasses a circular shape with a determined radius (see methods in the paper). The predicted core areas are stored as “**pred_index_StationName_ImageName.tif**” files in the “**prediction(50\75_hard\normal)**” folders. The calculated “**StationName_occurrence99.tif**” files in the “**occurrence_all**” folder are based on the predicted core areas and correspond to individual stations.


### Step 1: Data preparation - [1-Preprocessing-test_withLocation.ipynb]
There are three main data, the satellite images (number of images = 7,172), the label of core area plumes (Core50 number of images = 4,786; Core75 number of images = 3,841); and the label of mixed area plumes (number of images = 7,172). The WST increment images (delta/delta_StationName_ImageName.tif; e.g., delta_Angra_LC08_218076_20130606.tif) which are used to train the model should be annotated with the core area plumes (e.g., sampleAnnotation50\train5_all.shp), while the background areas that are annotated should be separately marked and stored as shapefiles (e.g., sampleAnnotation50\area_all.shp). We trained two separate deep learning models (referred to as “Core50” and “Core75”, respectively) to compare their performance based on different ways to generate the training dataset. In this study, the core area polygons for model training were generated through a series of rules followed by manual inspection. (see the Methods of this article). 

The required shapefiles are available in the sampleAnnotation5 and sampleAnnotation75, including the labelled background areas (e.g., area_all.shp), the core plume polygons (e.g., core5_all.shp) and the mixed plume polygons (e.g., plus1_all.shp). Note that those Datasets and Polygons's named with "hard" (e.g., sampleAnnotation5_hard) did not participate in the training, validation, and testing of the models. They represent those conditions where threshold segmentation methods are not suitable. We provide them to represent the importance of our proposed model in differentiating thermal pollution of nuclear power plants.

Then, declare the input paths and other relevant configurations in notebooks/config/Preprocessing_withLocation.py file. After declaring the required paths, run the first notebook notebooks/1-Preprocessing-test_withLocation.ipynb to extract these background areas with the contained object polygons as image files. Finally, write the extracted images (extractWithLocation\extract50_withLocation\delta_index_StationName_ImageName.tif; e.g., delta_0_Angra_LC08_218076_20130708.tif) and their corresponding annotations file (extractWithLocation\extract50_withLocation\annotation_index_StationName_ImageName.tif; e.g., annotation_0_Angra_LC08_218076_20130708.tif).

### Step 2: Model training - [2-UNetTraining-test_withLocation.ipynb]
Train the UNet model with the extracted images using the UNetTraining_withLocation.ipynb notebook. Declare the relevant configuration in notebooks/config/UNetTraining_withLocation.py. In case you use an independent test dataset, you can use Auxiliary-1-UNetEvaluation-test_withLocation.ipynb to evaluate the performance of the model. Step-1 data preparation can also be used to extract the test set. In order to alleviate the imbalance data size among different Landsat missions, you can use SamplingByLandsatSeries.ipynb notebook to generate frame_list.json for train/validation/test dataset dividing. The trained models will be saved in notebooks\saved_models\UNet.

### Step 3: Analyzing images - [3-RasterAnalysis-test_withLocation.ipynb]
Next, use the trained model to analyze images (generate binary masks of the core plumes) using 3-RasterAnalysis-test_withLocation.ipynb notebook. The path to the trained model and satellite images should be declared in the notebooks/config/RasterAnalysis_withLocation.py. The model-predicted core plumes will be saved in prediction50_normal/prediction50_hard/prediction75_normal/prediction75_hard (naming format: pred50_index_StationName_ImageName.tif; e.g., pred50_0_Angra_LC08_218076_20130708.tif). The comparison between “extract(50\75)_withLocation” and “prediction(50\75)_normal” represents the segmentation difference between traditional threshold methods and our proposed deep-learning based model.

The occurrence_all file include the historical frequency (>0.01) of core plumes for 74 nuclear power plant outlets (naming format: StationName_occurrence99.tif; e.g., Angra_occurrence99.tif), manual screening were conducted to exclude 18 images that are hard to recognize the core plume areas (mostly in "hard" group) before occurrence calculation.

## A note on processdures and the data source
This code relies on satellite images with two channels (WST increment band and Euclidean distance band). In case your data is available in multiple channels, then the notebooks and core libraries need to be adapted accordingly. 